import os
import time
import datetime
from lxml import etree
import psycopg2

'''
Function for calculating the elapsed time of an action

Input:  start time type time
        end time type time

Output: elapsed time in seconds
'''
def elapsed_time(start, end):
    elapsed = round(((end - start) % 60), 2)

    return (str(elapsed) + 'seconds')

'''
Variable for DBLP file

Input: a file in XML format

Source file location: http://dblp.uni-trier.de/xml/

File version date: 11 March 2017
'''
dblp_xml_file_name = 'dblp-2017-03-03.xml'

'''
Variable for the location of DBLP file.
In our program, we have a directory named 'data'.  Inside this directory, there are two files:
(1) dblp.dtd and (2) dblp.xml.  The (1) is the data definition for the xml and the (2) is the dblp data.
'''
file_location = os.path.abspath(os.path.join('data', dblp_xml_file_name))

'''
Variable for the DBLP XML file using its DTD file.
'''
parser = etree.XMLParser(dtd_validation=True)

'''
Initializing time and date markers for parsing the XML file
'''
parse_start_time = time.time()
parse_start_date = datetime.datetime.now()
print(str(parse_start_date) + ': Start to parse the xml data...')

'''
Parsing the DBLP XML file
'''
doc = etree.parse(file_location, parser)

'''
Ending time and date markers for parsing the XML file
'''
parse_end_time = time.time()
parsed_end_date = datetime.datetime.now()
print('Parsed within ' + elapsed_time(parse_start_time, parse_end_time) + ' and ended on ' + str(parsed_end_date))

'''
Getting the root of the DBLP XML file
'''
root = doc.getroot()

'''
Initializing the required counter for collecting data migration statistics
'''
article_counter = 0
inproceedings_counter = 0
proceedings_counter = 0
book_counter = 0
incollection_counter = 0
phdthesis_counter = 0
mastersthesis_counter = 0
www_counter = 0

'''
Establishing connection to PostgreSQL RDBMS.
In this program, I use PostgreSQL DBMS to store the DBLP data.
The name of the database is "dblp".
The database user that I use in this progam is named "satrio".
At this program, I do not use any password to access the database.
I use psycopg2 python library as the PostgreSQL adapter.

The syntax for establishing connection:
conn = psycopg2.connect("dbname=database-name user=database-username password=user-password-if-any")
'''
conn = psycopg2.connect("dbname=dblp user=satrio")
cur = conn.cursor()

'''
Initializing time and date marker for iterating the root's children
'''
iteration_start_time = time.time()
iteration_start_date = datetime.datetime.now()
print(str(iteration_start_date) + ': Start the migration process...')

'''
Iterating root's children.
The children composed of article|inproceedings|proceedings|book|incollection|phdthesis|mastersthesis|www
'''
for children in root:
    '''
    Initializing child's attributes.
    IMPORTANT: not all children have these attributes but we initialized them anyway so their are there when they are
    needed.
    '''
    key = None
    mdate = None
    publtype = None
    reviewid = None
    rating = None

    '''
    Initializing child's sub-elements.
    Some sub-elements are initialized as empty lists due to the nature of the data of those sub-elements
    '''
    editor = None
    title = None
    booktitle = None
    pages = None
    year = None
    address = None
    journal = None
    volume = None
    number = None
    month = None
    url = None
    cdrom = None
    publisher = None
    note = None
    crossref = None
    isbn = None
    series = None
    school = None
    chapter = None
    author = []
    cite = []
    ee = []

    '''
    Iterating through the child's attribute for assigning the attribute value to a variable
    '''
    for attribute_name, attribute_value in children.items():
        if(attribute_name == 'key'):
            key = attribute_value
        if(attribute_name == 'mdate'):
            mdate = attribute_value
        if(attribute_name == 'publtype'):
            publtype = attribute_value
        if(attribute_name == 'reviewid'):
            reviewid = attribute_value
        if(attribute_name == 'rating'):
            rating = attribute_value

    '''
    Retrieving DBLP data value through iterating the root's grandchildren
    The following are the root's children:
    - author
    - editor
    - title
    - booktitle
    - pages
    - year
    - address
    - journal
    - volume
    - number
    - month
    - url
    - ee
    - cdrom
    - cite
    - publisher
    - note
    - crossref
    - isbn
    - series
    - school
    - chapter
    Some of these grandchildren's value may be NULL
    '''
    for grand_children in children:
        if(grand_children.tag == 'author'):
            '''
            Intializing time marker for checking author data in the database.
            '''
            check_author_start = time.time()

            print('Checking the existence of author data in the database...')

            '''
            Querying data in the database.
            Input: key from the children's attribute
                   author from the value of the grand children's tag
            '''
            query = 'SELECT key, author FROM author WHERE key = %s AND author = %s'
            cur.execute(query, (str(key), str(grand_children.text)))

            '''
            Ending time marker for checking author data in the database.
            '''
            check_author_end = time.time()

            print('Checked within ' + elapsed_time(check_author_start, check_author_end))

            '''
            Check the query result.
            If the author has not yet exist in the database then we add the new author to the database
            Else we print out a notification which says that the author already existed in the database and we ignore it.
            '''



'''
Ending time and date marker for iterating the root's childres
'''
iteration_end_time = time.time()
iteration_end_date = datetime.datetime.now()
print('The migration process finished within ' + elapsed_time(iteration_start_time, iteration_end_time) + ' and ended on ' + str(iteration_end_date))